{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts used to gather, preprocess and manipulate the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv2.namedWindow(\"preview\")\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): \n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "image_counter = 1\n",
    "\n",
    "while rval:\n",
    "    cv2.imshow(\"preview\", frame)\n",
    "    rval, frame = vc.read()\n",
    "    key = cv2.waitKey(20)\n",
    "\n",
    "    if cv2.getWindowProperty(\"preview\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "        break\n",
    "\n",
    "    if key == ord('s'):  \n",
    "        image_filename = f\"images_X2/image_{image_counter}.png\"\n",
    "        cv2.imwrite(image_filename, frame)\n",
    "        image_counter += 1\n",
    "\n",
    "    if key == 27:  # Exit on ESC\n",
    "        break\n",
    "\n",
    "vc.release()\n",
    "cv2.destroyWindow(\"preview\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captures pirctures by pressing S, and gives them a name based on a defined patern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_directory = 'images_X2'  \n",
    "\n",
    "def resize_images(src_dir):\n",
    " \n",
    "    files = os.listdir(src_dir)\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(src_dir, file_name)\n",
    "        \n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "        \n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            print(f\"Unable to read image {file_path}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        resized_image = cv2.resize(image, (640,640), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        cv2.imwrite(file_path, resized_image)\n",
    "        print(f\"Resized and saved {file_path}\")\n",
    "\n",
    "resize_images(source_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizes the images in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_files_across_directories(directories, new_name_pattern, start_index=0):\n",
    "\n",
    "    current_index = start_index\n",
    "    \n",
    "    for directory_path in directories:\n",
    "        if not os.path.isdir(directory_path):\n",
    "            print(f\"Directory not found: {directory_path}\")\n",
    "            continue\n",
    "        \n",
    "        files = os.listdir(directory_path)\n",
    "        files = [f for f in files if os.path.isfile(os.path.join(directory_path, f))]\n",
    "        \n",
    "        files.sort()\n",
    "        \n",
    "        for filename in files:\n",
    "            new_filename = new_name_pattern.format(current_index + 1)\n",
    "            old_file_path = os.path.join(directory_path, filename)\n",
    "            new_file_path = os.path.join(directory_path, new_filename)\n",
    "\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed '{filename}' to '{new_filename}'\")\n",
    "            \n",
    "            current_index += 1\n",
    "\n",
    "directories = ['train_yasmin', 'images_X', 'images_X2', 'images_O']\n",
    "new_name_pattern = 'image_{:03d}.jpg'  \n",
    "start_index = 1   \n",
    "\n",
    "rename_files_across_directories(directories, new_name_pattern, start_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For multiple collaborators, to solve the image name conflicts, we can rename images across multiple files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def split_dataset(image_dir, label_dir, train_img_dir, train_label_dir, val_img_dir, val_label_dir, train_ratio=0.9):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets, and moves unmatched images/labels into the validation set.\n",
    "    \n",
    "    Args:\n",
    "    - image_dir (str): Directory containing the images.\n",
    "    - label_dir (str): Directory containing the labels.\n",
    "    - train_img_dir (str): Directory to store the training images.\n",
    "    - train_label_dir (str): Directory to store the training labels.\n",
    "    - val_img_dir (str): Directory to store the validation images.\n",
    "    - val_label_dir (str): Directory to store the validation labels.\n",
    "    - train_ratio (float): Ratio of the dataset to be used for training (default 0.9).\n",
    "    \"\"\"\n",
    "    # Create the destination directories if they don't exist\n",
    "    os.makedirs(train_img_dir, exist_ok=True)\n",
    "    os.makedirs(train_label_dir, exist_ok=True)\n",
    "    os.makedirs(val_img_dir, exist_ok=True)\n",
    "    os.makedirs(val_label_dir, exist_ok=True)\n",
    "\n",
    "    # List all image and label files\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))])\n",
    "    label_files = sorted([f for f in os.listdir(label_dir) if os.path.isfile(os.path.join(label_dir, f))])\n",
    "\n",
    "    # Extract base filenames (without extensions) for matching images with labels\n",
    "    image_basenames = {os.path.splitext(f)[0]: f for f in image_files}\n",
    "    label_basenames = {os.path.splitext(f)[0]: f for f in label_files}\n",
    "\n",
    "    # Matched images and labels\n",
    "    matched_files = set(image_basenames.keys()) & set(label_basenames.keys())\n",
    "\n",
    "    # Unmatched images and labels\n",
    "    unmatched_images = set(image_basenames.keys()) - set(label_basenames.keys())\n",
    "    unmatched_labels = set(label_basenames.keys()) - set(image_basenames.keys())\n",
    "\n",
    "    # Combine matched images and labels into a list for splitting\n",
    "    matched_list = [(image_basenames[name], label_basenames[name]) for name in matched_files]\n",
    "    \n",
    "    # Shuffle the files to randomize the split\n",
    "    random.shuffle(matched_list)\n",
    "\n",
    "    # Calculate the split index for the training set\n",
    "    split_index = int(len(matched_list) * train_ratio)\n",
    "\n",
    "    # Move matched files to the appropriate directories\n",
    "    for i, (img_file, label_file) in enumerate(matched_list):\n",
    "        img_src_path = os.path.join(image_dir, img_file)\n",
    "        label_src_path = os.path.join(label_dir, label_file)\n",
    "\n",
    "        if i < split_index:\n",
    "            # Move to train directories\n",
    "            img_dest_path = os.path.join(train_img_dir, img_file)\n",
    "            label_dest_path = os.path.join(train_label_dir, label_file)\n",
    "        else:\n",
    "            # Move to validation directories\n",
    "            img_dest_path = os.path.join(val_img_dir, img_file)\n",
    "            label_dest_path = os.path.join(val_label_dir, label_file)\n",
    "\n",
    "        # Move image and label\n",
    "        shutil.move(img_src_path, img_dest_path)\n",
    "        shutil.move(label_src_path, label_dest_path)\n",
    "        print(f\"Moved matched: {img_file} and {label_file} to {'train' if i < split_index else 'valid'}\")\n",
    "\n",
    "    # Move unmatched images to validation\n",
    "    for img_name in unmatched_images:\n",
    "        img_src_path = os.path.join(image_dir, image_basenames[img_name])\n",
    "        img_dest_path = os.path.join(val_img_dir, image_basenames[img_name])\n",
    "        shutil.move(img_src_path, img_dest_path)\n",
    "        print(f\"Moved unmatched image: {image_basenames[img_name]} to validation\")\n",
    "\n",
    "    # Move unmatched labels to validation\n",
    "    for label_name in unmatched_labels:\n",
    "        label_src_path = os.path.join(label_dir, label_basenames[label_name])\n",
    "        label_dest_path = os.path.join(val_label_dir, label_basenames[label_name])\n",
    "        shutil.move(label_src_path, label_dest_path)\n",
    "        print(f\"Moved unmatched label: {label_basenames[label_name]} to validation\")\n",
    "\n",
    "# Example usage\n",
    "image_dir = 'datasets/training/images'   # Original images directory\n",
    "label_dir = 'datasets/training/labels'   # Original labels directory\n",
    "\n",
    "train_img_dir = 'train/images'  # Training images directory\n",
    "train_label_dir = 'train/labels'  # Training labels directory\n",
    "val_img_dir = 'valid/images'  # Validation images directory\n",
    "val_label_dir = 'valid/labels'  # Validation labels directory\n",
    "\n",
    "split_dataset(image_dir, label_dir, train_img_dir, train_label_dir, val_img_dir, val_label_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits the dataset into training and validation sets, and moves unmatched images into the validation set\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
